name: PubMed OA Literature Mining

on:
  schedule:
    - cron: '0 6 * * *'  # Daily at 6 AM UTC (1 AM EST)
  workflow_dispatch:  # Manual trigger for testing

jobs:
  scrape-and-analyze:
    runs-on: ubuntu-latest
    timeout-minutes: 30
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v3
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
      
      - name: Create directories
        run: |
          mkdir -p data/pdfs logs
      
      - name: Run PubMed scraper
        working-directory: .
        env:
          UNPAYWALL_EMAIL: parker@stroomai.com
          PUBMED_EMAIL: parker@stroomai.com
          PUBMED_TOOL: PubMedLiteratureMining
          MAX_ARTICLES_PER_RUN: 5000
          RELEVANCE_THRESHOLD: 70
        run: |
          python scripts/pubmed_scraper.py
      
      - name: Analyze and notify
        working-directory: .
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          GITHUB_REPO_OWNER: ${{ github.repository_owner }}
          GITHUB_REPO_NAME: ${{ github.event.repository.name }}
          RELEVANCE_THRESHOLD: 70
        run: |
          python scripts/analyze_and_notify.py
      
      - name: Commit article data and review queue
        run: |
          git config user.name "PubMed Monitor"
          git config user.email "actions@github.com"
          
          # Commit article data
          if [ -d data/articles ]; then
            git add data/articles/
          fi
          
          # Commit SQLite database (literature quality system)
          if [ -f data/literature.db ]; then
            git add data/literature.db
          fi
          
          # Commit review queue (CRITICAL: Dashboard needs this file)
          if [ -f data/review_queue.json ]; then
            git add data/review_queue.json
          fi
          
          if ! git diff --staged --quiet; then
            git commit -m "ðŸ“š Update article database and review queue - $(date +%Y-%m-%d)" || echo "No changes to commit"
            git push || echo "Nothing to push"
          fi
      
      - name: Generate and commit daily summary
        run: |
          git config user.name "PubMed Monitor"
          git config user.email "actions@github.com"
          
          if [ -f LATEST_FINDINGS.md ]; then
            git add LATEST_FINDINGS.md
            
            if ! git diff --staged --quiet; then
              git commit -m "ðŸ“Š PubMed Daily Summary - $(date +%Y-%m-%d)
              
              - Articles processed: $(cat logs/daily_count.txt 2>/dev/null || echo 'N/A')
              - Paywalled articles: $(cat logs/paywalled_count.txt 2>/dev/null || echo 'N/A')
              - Predictive factors: $(cat logs/factors_count.txt 2>/dev/null || echo 'N/A')"
              git push
            else
              echo "No changes to commit"
            fi
          fi
      
      - name: Upload logs
        if: always()
        uses: actions/upload-artifact@v3
        with:
          name: scraper-logs-${{ github.run_number }}
          path: |
            logs/
            LATEST_FINDINGS.md
          retention-days: 30

